{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c197739-8917-4ec8-8cff-96165fc6f2a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"/Workspace/Users/1dt003@msacademy.msai.kr/team4-CICD/src\")\n",
    "\n",
    "from src.config_loader import load_config\n",
    "from src.data_preprocessor import preprocess_dataframe, merge_batch_recent\n",
    "from src.model_trainer import build_preprocessor, train_models\n",
    "from src.mlflow_manager import init_experiment, log_model_mlflow\n",
    "from src.model_serving import predict_with_model\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "# ==============================\n",
    "# Spark 세션\n",
    "# ==============================\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ==============================\n",
    "# Config 로드\n",
    "# ==============================\n",
    "config = load_config(\"/Workspace/Users/1dt003@msacademy.msai.kr/team4-CICD/configs/config_v2.json\")\n",
    "\n",
    "jdbc_url = config['jdbc_url']\n",
    "connection_properties = config.get('connection_properties')\n",
    "batch_table = config['batch_table']\n",
    "recent_table = config['recent_table']\n",
    "exclude_cols = config.get('exclude_cols', ['learnerID','testID','correct_cnt','items_attempted'])\n",
    "categorical_candidates = config.get('categorical_candidates', ['gender','grade'])\n",
    "rename_map = config.get('rename_map', {'pred_realScore_clean': 'realScore_clean'})\n",
    "drop_cols = config.get('drop_cols', ['percent_rank','grade_percentile_calc'])\n",
    "target = config.get(\"target\", \"realScore_clean\")\n",
    "\n",
    "# ==============================\n",
    "# 환경변수로 모델/실험/타겟 정보\n",
    "# ==============================\n",
    "\n",
    "PREDICT_EXPERIMENT = os.environ.get(\"PREDICT_EXPERIMENT\") or \"/Workspace/Users/1dt003@msacademy.msai.kr/team4_pred_experiment\"\n",
    "BASE_MODEL_NAME = os.environ.get(\"BASE_MODEL_NAME\") or \"team4-pred-model\"\n",
    "\n",
    "# ==============================\n",
    "# 데이터 로드 & 병합\n",
    "# ==============================\n",
    "df_batch = spark.read.jdbc(url=jdbc_url, table=batch_table, properties=connection_properties)\n",
    "df_recent = spark.read.jdbc(url=jdbc_url, table=recent_table, properties=connection_properties)\n",
    "\n",
    "df_merge = merge_batch_recent(\n",
    "    df_batch,\n",
    "    df_recent,\n",
    "    rename_map=config.get('rename_map', {'pred_realScore_clean': target}),\n",
    "    drop_cols=config.get('drop_cols', ['percent_rank','grade_percentile_calc'])\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# 전처리\n",
    "# ==============================\n",
    "df_processed, categorical_cols = preprocess_dataframe(df_merge, categorical_candidates=categorical_candidates)\n",
    "\n",
    "# ==============================\n",
    "# feature/target 분리\n",
    "# ==============================\n",
    "feature_cols = [c for c in df_processed.columns if c not in ([target] + exclude_cols)]\n",
    "X = df_processed[feature_cols]\n",
    "y = df_processed[target]\n",
    "\n",
    "# ==============================\n",
    "# train/test split\n",
    "# ==============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==============================\n",
    "# 전처리 파이프라인 생성\n",
    "# ==============================\n",
    "preprocessor = build_preprocessor(X_train, categorical_cols)\n",
    "\n",
    "# ==============================\n",
    "# 모델 학습\n",
    "# ==============================\n",
    "train_results = train_models(X_train, y_train, X_test, y_test, preprocessor)\n",
    "\n",
    "print(\"✅ 학습 완료. 평가 결과:\")\n",
    "for name, res in train_results['results'].items():\n",
    "    print(f\"{name}: RMSE={res['rmse']:.4f}, MAE={res['mae']:.4f}, R2={res['r2']:.4f}\")\n",
    "\n",
    "# ==============================\n",
    "# MLflow 등록\n",
    "# ==============================\n",
    "\n",
    "init_experiment(PREDICT_EXPERIMENT)\n",
    "\n",
    "log_model_mlflow(\n",
    "    best_name=train_results['best_name'],\n",
    "    best_model=train_results['best_model'],\n",
    "    results=train_results['results'],\n",
    "    model_name=BASE_MODEL_NAME\n",
    ")\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# 최신 None stage 모델 가져오기\n",
    "latest_versions = client.get_latest_versions(name=BASE_MODEL_NAME, stages=[\"None\"])\n",
    "if not latest_versions:\n",
    "    raise ValueError(f\"No versions found for {BASE_MODEL_NAME}\")\n",
    "\n",
    "latest_version_num = max([int(v.version) for v in latest_versions])\n",
    "\n",
    "\n",
    "print(f\"✅ 모델 {BASE_MODEL_NAME} version {latest_version_num}를 Staging stage로 전환 완료\")\n",
    "\n",
    "# ==============================\n",
    "# 샘플 서빙 테스트\n",
    "# ==============================\n",
    "sample_preds = predict_with_model(train_results['best_model'], X_test.head(5), feature_cols)\n",
    "print(\"샘플 예측값:\\n\", sample_preds)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "register_model_notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
